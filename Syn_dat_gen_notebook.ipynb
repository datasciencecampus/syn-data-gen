{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Dr C Joshi\n",
    "\n",
    "#### This notebook is based on the work DataSynthesizer: Privacy-Preserving Synthetic Datasets\n",
    "https://faculty.washington.edu/billhowe/publications/pdfs/ping17datasynthesizer.pdf\n",
    "\n",
    "The numerical code presented in this notebook is heavily based on open source code available here \n",
    "https://github.com/DataResponsibly/DataSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSynthesizer is the directory where the following parent modules exist:\n",
    "# DataSynthesizer consists of three high-level modules — DataDescriber, \n",
    "# DataGenerator and ModelInspector. The first, DataDescriber, investigates\n",
    "# the data types, correlations and distributions of the attributes in the \n",
    "# private dataset, and produces a data summary, adding noise to the distributions\n",
    "# to preserve privacy. DataGenerator samples from the summary computed by \n",
    "# DataDescriber and outputs synthetic data. ModelInspector shows an intuitive \n",
    "# description of the data summary that was computed by DataDescriber, allowing the data \n",
    "# owner to evaluate the accuracy of the summarization process and adjust any parameters, if desired.\n",
    "import os, sys\n",
    "sys.path.append(os.getcwd() + '/DataSynthesizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataDescriber import DataDescriber\n",
    "from DataGenerator import DataGenerator\n",
    "from ModelInspector import ModelInspector\n",
    "from lib.utils import read_json_file, display_bayesian_network\n",
    "from lib.utils import pairwise_attributes_mutual_information\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As noted in the original article above:\n",
    "# DataSynthesizer can operate in one of three modes:\n",
    "# In correlated attribute mode, we learn a differentially\n",
    "# private Bayesian network capturing the correlation structure\n",
    "# between attributes, then draw samples from this model to\n",
    "# construct the result dataset. In cases where the correlated \n",
    "# attribute mode is too computationally expensive or when there\n",
    "# is insufficient data to derive a reasonable model, one can use\n",
    "# independent attribute mode. In this mode, a histogram is derived\n",
    "# for each attribute, noise is added to the histogram to achieve\n",
    "# differential privacy, and then samples are drawn for each attribute.\n",
    "# Finally, for cases of extremely sensitive data, one can use random \n",
    "# mode that simply generates type-consistent random values for each attribute.\n",
    "\n",
    "mode_dict = {\"rand\": 'random_mode',\"inde\": 'independent_attribute_mode',\\\n",
    "           \"corr\": 'correlated_attribute_mode'}\n",
    "mode = input('Please choose a mode: ')\n",
    "try:\n",
    "    print(\"Chosen mode of synthetic data generation pipeline is \", mode_dict[mode])\n",
    "except KeyError:\n",
    "    print(\"The mode {} do not exist\".format(mode))\n",
    "    \n",
    "mode=mode_dict[mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "if os.path.exists(f'./out/{mode}/') and os.path.isdir(f'./out/{mode}/'):\n",
    "    shutil.rmtree(f'./out/{mode}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dataset: specify the location of the training dataset\n",
    "input_data = './data/dataset.csv'\n",
    "\n",
    "# location of two output files\n",
    "description_file = f'./out/{mode}/description.json'\n",
    "synthetic_data = f'./out/{mode}/sythetic_data.csv'\n",
    "\n",
    "Path(f'./out/{mode}/').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can have lots of nuances:\n",
    "# one has to investigate different \n",
    "# techniques to ensure the raw data\n",
    "# is ready for training the model\n",
    "\n",
    "# Read the training dataset\n",
    "df=pd.read_csv(input_data)\n",
    "print(df.dtypes)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can try different things to select\n",
    "# chosen datatypes\n",
    "\n",
    "#e.g.\n",
    "#df=df.select_dtypes(include='int64')\n",
    "\n",
    "# We use all the variables, but some columns \n",
    "# might be dirty\n",
    "\n",
    "#remove columns with all zeros\n",
    "df=df.loc[:, (df != 0).any(axis=0)]\n",
    "print('after removing all zero columns, the number of entries are {}'.format(df.shape))\n",
    "\n",
    "# remove nans: one could try something a little more clever too\n",
    "df=df.dropna(axis=1, how='all')\n",
    "print('after removing nans, the number of entries are {}'.format(df.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.loc[:,(df.sum(axis=0)==0)]\n",
    "\n",
    "\n",
    "# correlated attribute mode is expansive to compute\n",
    "if mode=='correlated_attribute_mode':\n",
    "    df=df.sample(8, axis=1)\n",
    "\n",
    "# save the clean(er) dataset in the data directory with a chosen name\n",
    "\n",
    "input_data = './data/dataset_short.csv'\n",
    "df.to_csv(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The domain of an attribute is the set of its legal values. \n",
    "# The data type is an important ingredient of the attribute\n",
    "# domain. DataSynthesizer supports four data types. The \n",
    "# system allows users to explicitly specify attribute \n",
    "# data types. If an attribute data type is not specified by the user,\n",
    "# it is inferred by the DataDescriber. For each attribute, \n",
    "# DataDescriber first detects whether it is numerical, and if so — whether\n",
    "# it is an integer or a float. If the attribute is non-numerical,\n",
    "# DataDescriber attempts to parse it as datetime. Any attribute \n",
    "# that is neither numerical nor datetime is considered a string.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# An attribute is categorical if its domain size is less than this threshold.\n",
    "\n",
    "# DataSynthesizer allows users to specify a data type, and state whether an attribute\n",
    "# is categorical, over-riding defaults on a per-attribute basis.\n",
    "# Fore more details refer to the paper above.\n",
    "\n",
    "# one can easily modify the threshold to adapt to the user need\n",
    "threshold_value = 30\n",
    "\n",
    "\n",
    "\n",
    "# A parameter in Differential Privacy. It roughly means that removing a row in the input dataset will not \n",
    "# change the probability of getting the same output more than a multiplicative difference of exp(epsilon).\n",
    "# Increase epsilon value to reduce the injected noises. Set epsilon=0 to turn off differential privacy.\n",
    "# DP has a massive role when generating synthetic data in the correlated mode.\n",
    "\n",
    "epsilon = 0.1\n",
    "\n",
    "# The maximum number of parents in Bayesian network, i.e., the maximum number of incoming edges.\n",
    "# Larger this number-more computationally intensive would be the calculations\n",
    "\n",
    "degree_of_bayesian_network = 1\n",
    "\n",
    "# Number of tuples generated in synthetic dataset.\n",
    "\n",
    "\n",
    "num_tuples_to_generate = np.int(df.shape[0]/4)\n",
    "# It can be set to any other number as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initiate the Datadescribe module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describer = DataDescriber(category_threshold=threshold_value)\n",
    "\n",
    "\n",
    "getattr(describer, 'describe_dataset_in_'+str(mode))(dataset_file=input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "getattr(describer, 'save_dataset_description_to_file')(description_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_bayesian_network: use when using the correlated attribute\n",
    "#display_bayesian_network(getattr(describer, 'bayesian_network'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initiate the Datagenerator module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synthetic data\n",
    "generator = DataGenerator()\n",
    "getattr(generator, 'generate_dataset_in_'+str(mode))(num_tuples_to_generate, description_file)\n",
    "\n",
    "getattr(generator,'save_synthetic_data')(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read both datasets using Pandas.\n",
    "input_df = pd.read_csv(input_data, skipinitialspace=True)\n",
    "synthetic_df = pd.read_csv(synthetic_data)\n",
    "\n",
    "# Read attribute description from the dataset description file.\n",
    "attribute_description = read_json_file(description_file)['attribute_description']\n",
    "\n",
    "inspector = ModelInspector(input_df, synthetic_df, attribute_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('shape of the actual data {}'.format(input_df.shape))\n",
    "print('shape of the synthetic data {}'.format(synthetic_df.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduce the number of columns in the synthetic data (for visual aid only)\n",
    "\n",
    "# DO TWEAK THIS BLOCK DEPENDING ON THE SIZE OF YOUR DATASET AND CHOSEN\n",
    "# MODE OF SYNTHETIC DATA GENERATION\n",
    "chosen_colmns=list(range(0,input_df.shape[1],15))\n",
    "\n",
    "if mode=='correlated_attribute_mode':\n",
    "    input_df_few_cols=input_df\n",
    "    synthetic_df_few_cols=synthetic_df\n",
    "    \n",
    "    \n",
    "else:\n",
    "    input_df_few_cols=input_df.iloc[:,chosen_colmns]\n",
    "    \n",
    "    synthetic_df_few_cols=synthetic_df.iloc[:,chosen_colmns]\n",
    "    \n",
    "print('shape of the reduced input data {}'.format(input_df_few_cols.shape))\n",
    "print('shape of the reduced synthetic data {}'.format(synthetic_df_few_cols.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in synthetic_df_few_cols.columns:\n",
    "    inspector.compare_histograms(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# compute mutual information\n",
    "private_mi = pairwise_attributes_mutual_information(input_df_few_cols)\n",
    "synthetic_mi = pairwise_attributes_mutual_information(synthetic_df_few_cols)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 10))\n",
    "fig.suptitle('Pairwise Mutual Information Comparison (Real vs Synthetic) using {}'.format(mode), fontsize=20)\n",
    "ax1, ax2 = axes\n",
    "\n",
    "im1 = ax1.matshow(private_mi,cmap=\"YlGnBu\")\n",
    "im2 = ax2.matshow(synthetic_mi,cmap=\"YlGnBu\")\n",
    "\n",
    "\n",
    "columns1=list(private_mi.columns)\n",
    " # Formatting for heat map 1.\n",
    "ax1.set_xticks(range(len(columns1)))\n",
    "ax1.set_yticks(range(len(columns1)))\n",
    "ax1.set_xticklabels(columns1)\n",
    "ax1.set_yticklabels(columns1)\n",
    "\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='left', rotation_mode='anchor')\n",
    "\n",
    "columns2=list(synthetic_mi.columns)\n",
    "# Formatting for heat map 2.\n",
    "ax2.set_xticks(range(len(columns2)))\n",
    "ax2.set_yticks(range(len(columns2)))\n",
    "ax2.set_xticklabels(columns2)\n",
    "ax2.set_yticklabels(columns2)\n",
    "\n",
    "plt.setp(ax2.get_xticklabels(), rotation=45, ha='left', rotation_mode='anchor')\n",
    "    \n",
    "\n",
    "fig.tight_layout()\n",
    "fig.colorbar(im1, fraction=0.045, pad=0.05, ax=ax1)\n",
    "fig.colorbar(im2, fraction=0.045, pad=0.05, ax=ax2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
